{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Website A/B Testing - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll get another chance to practice your skills at conducting a full A/B test analysis. It will also be a chance to practice your data exploration and processing skills! The scenario you'll be investigating is data collected from the homepage of a music app page for audacity.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Analyze the data from a website A/B test to draw relevant conclusions\n",
    "* Explore and analyze web action data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "Start by loading in the dataset stored in the file 'homepage_actions.csv'. Then conduct an exploratory analysis to get familiar with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hints:\n",
    "    * Start investigating the id column:\n",
    "        * How many viewers also clicked?\n",
    "        * Are there any anomalies with the data; did anyone click who didn't view?\n",
    "        * Is there any overlap between the control and experiment groups? \n",
    "            * If so, how do you plan to account for this in your experimental design?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of viewers: 6328\n",
      "Number of clickers: 1860\n",
      "Number of viewers who also clicked: 1860\n",
      "Number of anomalies: 0\n",
      "Number of users in both groups: 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('homepage_actions.csv')\n",
    "# Count the number of viewers and clickers\n",
    "viewers = df[df['action'] == 'view'].shape[0]\n",
    "clickers = df[df['action'] == 'click'].shape[0]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of viewers: {viewers}\")\n",
    "print(f\"Number of clickers: {clickers}\")\n",
    "print(f\"Number of viewers who also clicked: {df[df['action'] == 'click']['id'].nunique()}\")\n",
    "\n",
    "# Check for anomalies\n",
    "anomalies = df[df['action'] == 'click'][~df['id'].isin(df[df['action'] == 'view']['id'].unique())]\n",
    "print(f\"Number of anomalies: {anomalies.shape[0]}\")\n",
    "\n",
    "# Check for overlap between control and experiment groups\n",
    "control_ids = df[df['group'] == 'control']['id'].unique()\n",
    "experiment_ids = df[df['group'] == 'experiment']['id'].unique()\n",
    "overlap = set(control_ids) & set(experiment_ids)\n",
    "print(f\"Number of users in both groups: {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct a Statistical Test\n",
    "\n",
    "Conduct a statistical test to determine whether the experimental homepage was more effective than that of the control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -0.5828\n",
      "p-value: 0.5601\n"
     ]
    }
   ],
   "source": [
    "# Conduct a two-sample t-test\n",
    "from scipy.stats import ttest_ind\n",
    "# Calculate the click-through rates for the control and experiment groups\n",
    "control_df = df[df['group'] == 'control']\n",
    "experiment_df = df[df['group'] == 'experiment']\n",
    "control_ctr = control_df[control_df['action'] == 'click'].shape[0] / control_df[control_df['action'] == 'view'].shape[0]\n",
    "experiment_ctr = experiment_df[experiment_df['action'] == 'click'].shape[0] / experiment_df[experiment_df['action'] == 'view'].shape[0]\n",
    "t_stat, p_value = ttest_ind(control_df[control_df['action'] == 'click']['id'].unique(),\n",
    "                            experiment_df[experiment_df['action'] == 'click']['id'].unique())\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Results\n",
    "\n",
    "One sensible formulation of the data to answer the hypothesis test above would be to create a binary variable representing each individual in the experiment and control group. This binary variable would represent whether or not that individual clicked on the homepage; 1 for they did and 0 if they did not. \n",
    "\n",
    "The variance for the number of successes in a sample of a binomial variable with n observations is given by:\n",
    "\n",
    "## $n\\bullet p (1-p)$\n",
    "\n",
    "Given this, perform 3 steps to verify the results of your statistical test:\n",
    "1. Calculate the expected number of clicks for the experiment group, if it had the same click-through rate as that of the control group. \n",
    "2. Calculate the number of standard deviations that the actual number of clicks was from this estimate. \n",
    "3. Finally, calculate a p-value using the normal distribution based on this z-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "Calculate the expected number of clicks for the experiment group, if it had the same click-through rate as that of the control group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected clicks in experiment group: 838.02\n"
     ]
    }
   ],
   "source": [
    "expected_clicks = experiment_df[experiment_df['action'] == 'view'].shape[0] * control_ctr\n",
    "print(f\"Expected clicks in experiment group: {expected_clicks:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "Calculate the number of standard deviations that the actual number of clicks was from this estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: 3.66\n"
     ]
    }
   ],
   "source": [
    "# Calculate the actual number of clicks in the experiment group\n",
    "actual_clicks = experiment_df[experiment_df['action'] == 'click'].shape[0]\n",
    "\n",
    "# Calculate the variance for a binomial variable with n observations\n",
    "n = experiment_df[experiment_df['action'] == 'view'].shape[0]\n",
    "p = control_ctr\n",
    "variance = n * p * (1 - p)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "std_dev = variance ** 0.5\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = (actual_clicks - expected_clicks) / std_dev\n",
    "print(f\"Z-score: {z_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: \n",
    "Finally, calculate a p-value using the normal distribution based on this z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0001\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "Does this result roughly match that of the previous statistical test?\n",
    "\n",
    "> Comment: **These two p-values are very different, indicating that the two tests lead to different conclusions. a p-value of 0.001 would suggest strong evidence that the experimental homepage is more effective than the control homepage, while a p-value of 0.5601 would suggest that there is not a statistically significant difference in click-through rates between the two homepages.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you continued to get more practice designing and conducting AB tests. This required additional work preprocessing and formulating the initial problem in a suitable manner. Additionally, you also saw how to verify results, strengthening your knowledge of binomial variables, and reviewing initial statistical concepts of the central limit theorem, standard deviation, z-scores, and their accompanying p-values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
